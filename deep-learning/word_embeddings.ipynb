{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743b03ea-f8e2-48fd-88db-dc7b0ff7375b",
   "metadata": {},
   "source": [
    "## Learning about word embeddings\n",
    "\n",
    "Reference: DLS course and https://huggingface.co/spaces/hesamation/primer-llm-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9b9213-7a3e-493c-9a8b-6bc22991ed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-10 15:09:02--  https://figshare.com/ndownloader/files/10798046\n",
      "Resolving figshare.com (figshare.com)... 52.211.194.125, 54.154.228.204, 18.202.40.53, ...\n",
      "Connecting to figshare.com (figshare.com)|52.211.194.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10798046/GoogleNewsvectorsnegative300.bin?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20250410/eu-west-1/s3/aws4_request&X-Amz-Date=20250410T150902Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=faaadecb6b47e9a1117f6efb097d25c7f22c00113a0fd3166c9456d41fff4ba1 [following]\n",
      "--2025-04-10 15:09:02--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10798046/GoogleNewsvectorsnegative300.bin?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20250410/eu-west-1/s3/aws4_request&X-Amz-Date=20250410T150902Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=faaadecb6b47e9a1117f6efb097d25c7f22c00113a0fd3166c9456d41fff4ba1\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 3.5.64.231, 52.218.89.43, 3.5.64.189, ...\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|3.5.64.231|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3644258522 (3.4G) [binary/octet-stream]\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   3.39G  28.4MB/s    in 2m 9s   \n",
      "\n",
      "2025-04-10 15:11:12 (27.0 MB/s) - ‘GoogleNews-vectors-negative300.bin’ saved [3644258522/3644258522]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c \"https://figshare.com/ndownloader/files/10798046\" -O GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99773d7-e7f6-4c2b-9f7a-2c046843d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gensim) (1.10.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
      "Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.3 smart-open-7.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c72d6ff-16ca-4d8b-8182-14c443dac704",
   "metadata": {},
   "source": [
    "### With Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06ab336-fdaf-48c1-ae4e-606bb5e0f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b769687d-f6ad-4f53-bb60-8af222467539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding size: 300\n",
      "The vocabulary size: 3000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('gynecologist', 0.7093892097473145),\n",
       " ('nurse', 0.6477287411689758),\n",
       " ('doctors', 0.6471460461616516),\n",
       " ('physician', 0.6438996195793152),\n",
       " ('pediatrician', 0.6249487996101379)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The embedding size: {model.vector_size}\")\n",
    "print(f\"The vocabulary size: {len(model)}\")\n",
    "\n",
    "# italy - rome + london = england\n",
    "model.most_similar(positive=['london', 'italy'], negative=['rome'])\n",
    "\n",
    "### OUTPUT ###\n",
    "[('england', 0.5743448734283447),\n",
    " ('europe', 0.537047266960144),\n",
    " ('liverpool', 0.5141493678092957),\n",
    " ('chelsea', 0.5138063430786133),\n",
    " ('barcelona', 0.5128480792045593)]\n",
    "\n",
    "model.most_similar(positive=['woman', 'doctor'], negative=['man'])\n",
    "### OUTPUT ###\n",
    "[('gynecologist', 0.7093892097473145),\n",
    " ('nurse', 0.6477287411689758),\n",
    " ('doctors', 0.6471460461616516),\n",
    " ('physician', 0.6438996195793152),\n",
    " ('pediatrician', 0.6249487996101379)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "944836ee-f28b-434b-b730-ddb9c78d6424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[('Steven_Groeninger_spokesman', 0.5896883606910706), ('hand_Cendales', 0.5664861798286438), ('normality', 0.5241665840148926), ('normalized', 0.523280680179596), ('abnormal', 0.5226089358329773), ('usual', 0.49064669013023376), ('manager_Brandy_Kingsolver', 0.48467081785202026), ('features_Rozsos', 0.47671931982040405), ('normally', 0.47560444474220276), ('normalize', 0.47552597522735596)]\n"
     ]
    }
   ],
   "source": [
    "# print(model.vector_size)         # Should print 300\n",
    "\n",
    "word = \"normal\"\n",
    "print(word in model.key_to_index)  # Check if 'king' is in the vocabulary\n",
    "\n",
    "# # Get the embedding for a word\n",
    "# print(model['king'])\n",
    "\n",
    "# See most similar words\n",
    "print(model.most_similar(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb263faa-6c73-425d-8350-025c3b3942ae",
   "metadata": {},
   "source": [
    "### With BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ba301fa-26a8-4cb4-b691-221c285a1ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.1-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.30.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebda583d-b841-4bd8-ae3f-6231632c4396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load pretrained BERT (base uncased)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ensure it's on CPU\n",
    "device_id = \"cpu\"\n",
    "deviceid = \"gpu:0\"\n",
    "device = torch.device(device_id)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbe86f85-7a31-4d5a-883f-ae896c2fe3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=10)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Mean pooling over the token embeddings\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.numpy()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0530db28-74af-4ba0-b04a-ac4204967fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar words to 'king':\n",
      "queen      -> similarity: 0.9388\n",
      "prince     -> similarity: 0.9195\n",
      "throne     -> similarity: 0.9170\n",
      "woman      -> similarity: 0.8786\n",
      "soldier    -> similarity: 0.8751\n",
      "man        -> similarity: 0.8618\n",
      "dog        -> similarity: 0.8530\n",
      "president  -> similarity: 0.8456\n",
      "apple      -> similarity: 0.8353\n"
     ]
    }
   ],
   "source": [
    "# Target word or phrase\n",
    "query = \"king\"\n",
    "\n",
    "# Candidate words\n",
    "candidates = [\"queen\", \"man\", \"woman\", \"prince\", \"apple\", \"throne\", \"soldier\", \"president\", \"dog\"]\n",
    "\n",
    "# Compute embeddings\n",
    "query_vec = get_embedding(query)\n",
    "candidate_vecs = np.array([get_embedding(word) for word in candidates])\n",
    "\n",
    "# Cosine similarities\n",
    "similarities = cosine_similarity([query_vec], candidate_vecs)[0]\n",
    "\n",
    "# Rank and display top results\n",
    "top_indices = similarities.argsort()[::-1]\n",
    "print(f\"Top similar words to '{query}':\")\n",
    "for idx in top_indices:\n",
    "    print(f\"{candidates[idx]:<10} -> similarity: {similarities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c08dd-2b0c-45bc-90a6-177efad57148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
