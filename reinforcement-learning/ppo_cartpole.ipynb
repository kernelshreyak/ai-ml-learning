{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c5ce0a-986c-453c-8110-6c756a90d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder, SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3846add3-bccd-4112-86c2-3ad6b76f2df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Sanity checks\n",
    "# -----------------------------\n",
    "assert torch.cuda.is_available(), \"CUDA not available\"\n",
    "print(\"Using GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97d7422-3f79-4c07-a7c6-a54ae707c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "VIDEO_DIR = \"./rl_videos\"\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d44b18ac-b724-4c34-b838-793d992a7279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 14987 |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 2     |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12734       |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007761392 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00019     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 12139        |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063496158 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.671       |\n",
      "|    explained_variance   | 0.0213       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11798        |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073466087 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.651       |\n",
      "|    explained_variance   | 0.0481       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    value_loss           | 58.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 11637       |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005655147 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.626      |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 75.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11558        |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046921843 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.609       |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    value_loss           | 87           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 11522        |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042980807 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.592       |\n",
      "|    explained_variance   | 0.236        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    value_loss           | 91.6         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Base environment (for training)\n",
    "# -----------------------------\n",
    "def make_env():\n",
    "    return gym.make(\"CartPole-v1\")\n",
    "\n",
    "n_envs = 32  # matches your CPU cores\n",
    "\n",
    "env = SubprocVecEnv([make_env for _ in range(n_envs)])\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    device=\"cpu\",\n",
    "    n_steps=1024,\n",
    "    batch_size=2048,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Train\n",
    "# -----------------------------\n",
    "model.learn(total_timesteps=200_000)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b9bd71e-7757-4755-b40f-495d59a843a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to /home/shreyak/rl_videos/ppo-cartpole-step-0-to-step-500.mp4\n",
      "MoviePy - Building video /home/shreyak/rl_videos/ppo-cartpole-step-0-to-step-500.mp4.\n",
      "MoviePy - Writing video /home/shreyak/rl_videos/ppo-cartpole-step-0-to-step-500.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /home/shreyak/rl_videos/ppo-cartpole-step-0-to-step-500.mp4\n",
      "Video saved to ./rl_videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
    "\n",
    "def make_eval_env():\n",
    "    return gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "eval_env = DummyVecEnv([make_eval_env])\n",
    "\n",
    "eval_env = VecVideoRecorder(\n",
    "    eval_env,\n",
    "    VIDEO_DIR,\n",
    "    record_video_trigger=lambda step: step == 0,\n",
    "    video_length=500,\n",
    "    name_prefix=\"ppo-cartpole\",\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Run one episode and record\n",
    "# -----------------------------\n",
    "obs = eval_env.reset()\n",
    "\n",
    "for _ in range(500):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, _, dones, _ = eval_env.step(action)\n",
    "    if dones.any():\n",
    "        break\n",
    "\n",
    "eval_env.close()\n",
    "\n",
    "print(f\"Video saved to {VIDEO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd244e-1e29-470f-b357-084afd1f19b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
